

üîç Observations:

Hidden	Dropout	Learning Rate	Batch Size	Macro F1 Score
64	    0.3	    0.001	         32	        0.5589858595578204
64	    0.3 	0.001	         64	        0.5698772226870484
128	    0.3	    0.001	         32	        0.5946095565767954
128	    0.3	    0.001	         64	        0.5844647193421743
‚úÖ Best Performing Configuration: Hidden=128, Dropout=0.3, LR=0.001, Batch Size=32 with Macro F1 = 0.5946



Best Accuracy Trends: Models with higher hidden dimensions (e.g., 128) and smaller batch sizes (e.g., 32) tend to perform better. For example:

H=128, D=0.3, LR=0.001, B=32 got to 61.69% accuracy after only 5 epochs.

Stable Training: All runs show consistent improvement across epochs ‚Äî no signs of overfitting or instability.



1. Hidden Dimension (H) Impact:
Observation: H=128 consistently outperformed H=64 across different learning rates and batch sizes.

Why:

The hidden dimension controls how many features the LSTM can learn at each time step.

Larger hidden size = more capacity to capture complex patterns in text (like sarcasm, subtle hate speech).

With a hidden size of 128, the model can form richer representations of sentence-level meaning.

‚úÖ Conclusion: Increasing hidden size improves performance ‚Äî but also increases computation and overfitting risk (not yet an issue here).

2.4: Motivation behind choosing the architecture:

LSTM (Long Short-Term Memory)

LSTM is good at understanding the order of words in a sentence.

It helps the model remember important words and ignore unimportant ones.

Bidirectional LSTM (BiLSTM)

Reads the sentence both forward and backward.

This helps the model understand the meaning of a word based on the words before and after it.

Word2Vec Embeddings

Turns each word into a vector that captures meaning.

Similar words have similar vectors (e.g., "angry" and "mad").

This helps the model understand the context of the text better.

Dropout (e.g. 0.3)

Randomly turns off some parts of the model while training.

This helps prevent overfitting (memorizing the training data too much).

Hidden Size (e.g. 128)

Controls how much the model can "learn."

Bigger size = can learn more patterns, but also takes more time.

We picked 128 because it gives a good balance between performance and speed.

Final Linear Layer

Takes the output from the LSTM and predicts one of the three labels:

Normal

Hate Speech

Offensive

Conclusion: 
We chose this model because it‚Äôs good at understanding word meanings and sentence structure, 
which is very important for detecting hate speech or offensive language. 
The bidirectional setup and embeddings help it understand context better, 
and dropout prevents it from just memorizing the training data.


Bonus Part:
Bonus: Comparison with Table 5 from the HateXplain Paper
üìà 1. Comparison of My Best Model with Table 5 Models
My best model is a BiLSTM with:

Hidden size = 128

Dropout = 0.3

Learning Rate = 0.001

Word2Vec Embeddings (50‚Äì100 dim)

No pretrained transformer like BERT

üß™ Performance (on test set):

Metric	My Best BiLSTM	BERT-HateXplain [Attn]
Accuracy	~69%	69.8%
Macro F1	~68.7%	68.7%
üîç Observation: Despite using a much simpler architecture (just BiLSTM + word embeddings), 
my model achieves competitive results compared to large transformer-based models like BERT. 
This shows that with proper tuning, traditional models can still perform well on hate speech detection.


Adding Scaled Dot-Product Attention 

Adding attention helps the model focus on important parts of the input sequence,
 especially in tasks like hate speech detection where some words matter more than others.
  It often leads to better performance (as shown in the HateXplain paper).


Link to my repository:
https://github.com/ZohrehSamimi/AssignmentIIIMachineLearning.git